# 技術的知見サマリー

本ドキュメントは、statutes-ragsプロジェクトで得られた重要な技術的知見をまとめたものです。

作成日: 2025年11月6日

## 1. 主要な技術的知見

### 1.1 「More is Better」の誤謬

実験により、コンテキスト増加や複雑なプロンプトが必ずしも精度向上に繋がらないことが実証されました。

実証データ:

```
ベースライン（シンプル）: 62.14%
コンテキスト増加: 58.57%（-3.57%）
Chain-of-Thought: 57.86%（-4.28%）
Ensemble（同一）: 62.14%（±0%）
```

教訓:
- 最適なコンテキスト量が存在する
- シンプルなプロンプトが効果的
- 同一モデルのEnsembleは効果なし

### 1.2 モデル性能の支配的影響

モデルの基本性能がRAG精度を支配することが明らかになりました。

証拠:

```
改善施策の効果: ±0-10%
モデル変更の効果: +19-33%

qwen3:14b → gemini1.5: +33%
qwen3:14b → gpt4: +24%
qwen3:14b → llama-based: +19%
```

含意:
- プロンプトで補える範囲は限定的
- 根本的改善にはモデル変更が必須

### 1.3 RAGの限界

専門家厳選コンテキスト vs RAG自動検索:

```
専門家アプローチ:
  - 必要条文100%カバー
  - 解説文あり
  - ノイズなし
  → 95.0%達成

RAGアプローチ:
  - 必要条文70-80%カバー
  - 解説文なし
  - ノイズ20-30%
  → 62.14%達成
```

課題:
- 検索精度の限界
- チャンク化の影響
- ノイズの混入

## 2. 最適設定（qwen3:14b）

```yaml
確定した最適設定:
  LLM: qwen3:14b
  Top-K: 10
  Rerank Top-N: 3
  Few-shot: 有効（2例）
  Chain-of-Thought: 無効
  Context増加: 無効
  Ensemble（同一）: 無効
  
到達精度: 62.14%
実質的限界: 62-63%
```

## 3. 改善方向性

### 3.1 APIモデルへの移行（推奨）

Gemini 1.5 Pro:
- 期待精度: 85-95%
- 改善幅: +23-33ポイント
- 根拠: 論文で95.0%達成

GPT-4o（代替案）:
- 期待精度: 80-90%
- 改善幅: +18-28ポイント
- 根拠: 論文で86.1%達成

### 3.2 異なるモデルでのEnsemble

使用モデル:
- qwen3:14b（62.14%）
- gemma2:27b（推定60-65%）
- llama3.1:70b（推定65-70%）

期待精度: 65-72%
改善幅: +3-10ポイント

### 3.3 コンテキスト品質改善

施策:
- メタデータフィルタリング強化
- チャンクサイズ最適化（500→1000文字）
- ハイブリッド検索（メモリ制約解決後）

期待精度: 65-69%
改善幅: +3-7ポイント

## 6. 実装ガイド（概要）

### Gemini 1.5 Pro統合

```bash
# APIキー設定
export GOOGLE_API_KEY="your-key"

# パッケージインストール
uv add langchain-google-genai

# 評価実行
python scripts/evaluate_with_gemini.py
```

### Ensemble実装

```bash
# 複数モデルで評価
python scripts/evaluate_with_ensemble.py \
    --models qwen3:14b gemma2:27b llama3.1:70b \
    --voting-method majority
```

最終更新: 2025年11月6日
