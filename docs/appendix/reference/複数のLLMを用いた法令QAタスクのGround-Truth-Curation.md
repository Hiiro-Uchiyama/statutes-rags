複数のLLM を用いた法令QA タスクのGround Truth Curation
植松幸生1,2 大杉直也1
1 デジタル庁 2 東京理科大学 研究推進機構
{yukuemats, naosugi}@digital.go.jp  yukio@rs.tus.ac.jp
概要
本論文では，専門家が作成した法令に関するQA
の四者択一問題とそのGround Truth に対して，複数
の大規模言語モデル(LLM) を用いて検証すること
で，Ground Truth に誤りがあることを発見した．発
見する方式としては，Ground Truth を与えない状態
で，3 種類の異なるファウンデーションモデルの
LLM に 0-shot の設定で回答させた．生成された回
答から majority voting などの方法で結果を統合し，
すべての LLM の答えが一致しない問題を抽出し
たのち，再度専門家に確認を依頼し，一部問題で
Ground Truth が誤っていることを突き止めた．
1 はじめに
大規模言語モデル（LLM）は，自然言語処理タス
クのさまざまな分野で高い性能を発揮しており，特
に質問応答（QA）タスクにおいても注目を集めて
いる．法令に関するQA タスクでは，正確なGround
Truth（正解データ）が求められるが，人手で作成さ
れた正解データには誤りが含まれる可能性がある．
誤ったGround Truth は，モデルの評価結果や学習性
能に悪影響を与えるため，その信頼性を検証するこ
とが重要である．
本研究では，人手で作成した四者択一法令QA タ
スク（全140 問）に対して，複数の大規模言語モデ
ル（LLM）を用いて回答を生成し，その結果から
Ground Truth の妥当性を検証した．具体的には，複
数のLLM の回答の一致度やアンサンブル手法を通
じて「疑わしい」問題を特定した．その後，専門家
に再検証したところ，一部の問題において，既存の
Ground Truth が誤っていたことを発見した．
本研究の目的は，法令QA タスクにおけるGround
Truth の信頼性を高めるとともに，LLM の出力を用
いたデータ検証手法の有効性を示すことである．本
論文では，実験の設定，結果，および考察を通じて，
法令QA データの質向上に向けたアプローチについ
て述べる．
2 関連研究
本章では，Ground Truth Curation と，法令QA タス
クの関連研究について述べる．
Ground Truth のValidation やCuration は従来より多
くの分野で実施されてきた．例えば，Yoo[1] 等は，
in-context learning における入力とラベルの対応の重
要性について述べている．また，古くから Crowd
sourcing[2] を活用した，Ground Truth の生成，及び
その中で起きるバイアスや共謀などが課題になって
いる．本研究もこれらの分野と類似した研究である
が，Curation にLLM を利用している点と法判定QA
タスクという特殊なタスクである点が異なる．
法令を扱った QA タスクについてはこれまで多
くの関連研究やコンペティションが行われてきた．
我々が扱うタスクに最も近いのは日本の国家試験の
司法試験である1）．司法試験では，毎年短答式問題
が出題され，Q に対して正誤を付与するタスクが実
施されている．
コンピュータを対象にした法令に関するQA タス
クはこれまで多くのコンペティションが開催されて
きた．具体的には，Competition on Legal Information
Extraction and Entailment (COLIEE) が 10 年以上にわ
たり開催されている2）この中のタスクは，択一問題
も扱っており本研究と類似性が高い[3]．また，古
くはText REtrieval Conference(TREC) のLegal Track[4]
がある．TREC では，電子情報開示（e-discovery）に
関連する情報検索の課題に焦点を当て，法的文書か
ら関連情報を効率的に抽出するタスクを提供するも
のである．COLIEE や法令QA タスクと異なり，特
定の法令や判例に基づく選択肢問題ではなく，大規
模な文書集合内での情報探索が主題である．ただ
し，法的ドメインでの自動化技術の応用という点で
共通点がある．
1） https://www.moj.go.jp/jinji/shihoushiken/jinji08 00241.html
2） https://coliee.org/overview― 2486 ―言語処理学会 第31回年次大会 発表論文集（2025年3月）This work is licensed by the author(s) under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/).
Oxford University Press では，会社法に関する多肢
選択式問題が公開されている3）．これらは，法令に
関する四者択一形式の問題を含むものであり，本研
究が扱う法令QA タスクと形式的に類似している．
ただし，この問題集は教育目的で設計されており，
法令QA タスクの研究や評価のためのデータセット
として直接利用されることを意図しているわけでは
ない．
3 法令QA タスク
本章では，本研究で扱う法令QA タスクについて
説明する．法令QA タスクとは，法令に関連する質
問に対して正確に回答することを目的とした自然
言語処理タスクである．本研究では，主に2 つの目
的で利用するために法令QA タスクの正確なデータ
セットを作成している．
•LLM の学習向けバリデーションデータセット
•回答が四者択一形式の法令QA タスクのデータセット
法令に特化したLLM を作成するために，継続事
前学習などで利用するためのバリデーションデータ
セットが必要になる．その場合，法令を使った単純
なQA のデータセットが必要になる．また，日本語
で公開されている法令QA タスクが少ないため，正
確な法令QA タスクのデータセット自体にニーズが
あると考える．
3.1 本研究が扱う法令QA タスク
本研究における法令QA タスクでは，以下の特徴
を持つ設問を対象とする：
形式 4 者択一形式の選択問題
対象範囲 法令条文および関連する政令・解釈指針に基づいた
内容
質問の特性 文脈依存型の解釈を求める問題や，特定条文に関す
る知識の正確性を問う問題
具体的な QA は，コンテキスト，指示，問題文，
選択肢，アウトプット記載欄の5 つで構成されてい
る．コンテキストとは，問題文を解くために必要な
法令を抜粋したものである．本タスクでは，基本的
にこのコンテキストを読むことで正解を選択可能な
タスクになっている．指示とは，コンテキストに記
載した情報を用いて，選択肢をa,b,c,d から1 つ選べ
という指示である．問題文には法令 QA の Q が記
載され，その後に選択肢が a,b,c,d の形式で 4 つリ
ストされる．アウトプット記載欄は空欄で，そこに
LLM がアウトプットを入れる．
例えば，金融商品取引法に関連する問題では，法
令条文および政令の内容を基に，特定の条項や適用
範囲を正確に判断することが求められる．具体的に
は，以下のような質問が考えられる：
3） https://global.oup.com/uk/orc/law/company/roach4e/resources/mcqs/
金融商品取引法第2 条第2 項第5 号ニにおいて，有価証券
とみなさなくても公益または出資者の保護に支障を生じな
いとされる権利を選択肢から選べ．
選択肢としては，弁護士の業務を行う事業のみを
対象とする組合契約に基づく権利など，法令の詳細
な理解が必要な内容が含まれる．
このように，法令QA タスクは法令の文脈および
条文解釈に基づいた正確な回答生成が求められるた
め，Ground Truth の信頼性が特に重要である．
3.2 法令 QA タスクにおける Ground
Truth の作成とその問題点前節で示した法令QA タスクは高い専門性が求め
られるため複数の弁護士に作成を依頼する必要があ
るため非常にコストがかかる．また，Ground Truth
を作成する過程で以下のような問題が起きる可能性
がある．
1. コンテキスト(引用される文書) の間違い
2. 選択肢作成時の間違い
3. 単純な答えの間違い
引用される文書の間違いとは，コンテキストとし
て与える文書そのものが間違いだったり，不足して
いる例である．4 択の答えの作成間違いとは，4 択
の中に正答が存在しない，あるいは複数の答えが正
解になる場合である．最後に，単純な答えの間違い
とは，作成過程におけるバグ等の理由で，答えの指
定が間違えている場合である．
4 複数の LLM を用いた Ground
Truth Curation本研究では，複数の LLM を用いて Ground Truth
の間違いを発見する．これは，複数のLLM を用い
ることで，複数のAssessor に正解作成の依頼したこ
とと同様の効果があるかを検証する．
4.1 複数のLLM のアウトプットを統合す
るアンサンブル手法
複数のLLM の回答を統合する方法は，従来から
用いられている複数の機械学習を統合するアンサン
ブル学習[5] をLLM に応用する．表4 に，本研究で
用いたアンサンブル手法について比較する．
4.2 Majority voting
各モデルが選択肢 𝑗のいずれか1 つに対して1 票
投じ，その投じた票が最も大きい選択肢 𝑗を出力と
する方式である．
𝑆𝑗=
𝑛∑
𝑖=1
𝕀(𝑦𝑖=𝑗)
ここで:
𝕀(𝑦𝑖=𝑗)=
{1 モデル𝑖が選択肢 𝑗を選んだ場合
0 それ以外の場合― 2487 ―This work is licensed by the author(s) under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/).
本研究では，3 つのモデルを利用しているため，2
票以上が投じられた選択肢が選ばれることになる．
仮に 1 票ずつで 3 つの選択肢が同点となった場合
は，回答が最も上にある1 つが選択されたこととし
た．(a,b,c が1 票ずつの場合，a が選択される)
4.3 Soft voting
各モデルが選択肢 𝑗に対して出力する確率 𝑝𝑖,𝑗を
最終スコアとして算出する．具体的には，1 つの設
問𝑖に対する4 つの選択肢の合計が1 になるように
𝑝𝑖を調整する
𝑆𝑗=
𝑛∑
𝑖=1
𝑝𝑖,𝑗
この，𝑝を得るために以下に示すプロンプトを支持
に追加した．
以下の問題文に対する回答を、選択肢a、b、c、d に対し
て各選択肢の確率を足すと１になるように0-1 の間でコン
マに続いて出力してください。(ex. a:0.55,b:0.35,c:0,d:0.1)
稀に，合計が1 に満たないことや，答えが指定し
た形式でない場合等があったが，その場合は当該モ
デルの出力が無かったこととして実験を進めた．
4.4 モデルの信頼度を考慮した Soft
voting各モデルが選択肢 𝑗に対して出力する確率𝑝𝑖,𝑗に
モデルの信頼度 𝑤𝑖を重み付けし，最終スコアを計
算する方法である．前述したSoft voting では，各モ
デルの出力の信頼度が同じであることが前提となっ
ていたが，各モデルの精度が異なるため本手法を採
用した．
𝑆𝑗=
∑𝑛𝑖=1 𝑤𝑖·𝑝𝑖,𝑗∑𝑛𝑖=1 𝑤𝑖
ここで:
•𝑝𝑖,𝑗: モデル𝑖が選択肢 𝑗に出力する確率
•𝑤𝑖: モデル𝑖の重み（事前に設定された信頼度）
モデル𝑖の信頼度 𝑤𝑖を検証用データから得た正
解率に基づいて算出した．
𝑤𝑖=正解数𝑖
全検証問題数
表3 に，検証データで算出した各モデルの信頼度を
示す．この信頼度 𝑤に基づいて，後述の実験を進
めた．
5 実験
Ground Truth Curation の評価を実施するために大
きく2 つの実験を実施した．
実験1 法令QA タスクの難易度を確認する実験
実験2 Ground Truth Curation の結果を確認する実験
まず，実験1 として法令QA タスクの難易度を確
認するために，人手で作成したGround Truth を利用
して，各LLM および前述したアンサンブル手法の
正答率を算出する．次に，実験2 として実験1 を実
施した結果，LLM の正答に一貫性があり，Ground
Truth に疑義がある設問を抽出し，再度専門家に設
問とGround Truth の確認を実施する．
5.1 評価データセットの作成
本研究では，法令QA タスクの評価データセット
を，設問検証用として70 問，実験に利用するテスト
データとして140 問のデータセットを作成した．各
設問は，以下の情報を含む：
コンテキスト 必要な条文，政令の抜粋，簡単な解説文
質問文 「次の選択肢のうち正しいものはどれか」「誤っているも
のはどれか」など
選択肢a,b,c,d 1 つが正解，3 つが誤り
正解（Ground Truth) 専門家が判断
コンテキストには，回答に必要な条文や政令の抜
粋を入力し，専門家はこのコンテキストの情報のみ
で正解の選択肢を選ぶことが出来るようにした．後
述する実験では，このコンテキストを与えてLLM
に回答させた場合と，コンテキストを与えない場合
の両方を実施する．
検証用データの70 問は，前述した各モデルの信
頼度算出のために利用した．テストデータ 140 問
は，過去の文献で選択肢のOrder sensitivity 問題[6]
が指摘されており，それを取り除くために選択肢
a,b,c,d をランダマイズして同じ設問を4 つの設問に
し，560 問の設問を作成しテストデータとして利用
した．Ground Truth は，弁護士2 名の合意により作
成された．
5.2 実験に利用したモデル
実験では，以下の3 つのLLM を用いた．各ファ
ウンデーションモデル(以降モデル) を選定した理由
は，現在広く利用されているモデルであることと，
それぞれ独自のデータソースから作られていると想
定しており，日本語も扱えることが確認されている
からである．
モデルA (llama-based) llama 系列をベースに独自調整を施し
たモデル
モデルB (gpt4) OpenAI GPT-4 API を利用
モデルC (gemini1.5) Google 社が提供API を利用
5.3 実験1: 法令QA タスクの正答率
実験1 では，法令QA タスクの難易度と，専門家
の知識を有するような問題であるかを確認するため
に，専門家が作成したGround Truth を使って，各モ
デルの正答率を算出した．モデル𝑖の正答率 𝐴𝑖は以
下の式から算出される．
𝐴𝑖=正解数𝑖
全設問数 ×100
ここで，正解数𝑖は，モデル𝑖が正解した設問数で
あり，全設問数とは，データセット全体の設問数で
ある560 件となる．
表1 に，各モデルの正答率を示す．コンテキスト― 2488 ―This work is licensed by the author(s) under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/).
を与えた場合（関連する法令条文が提示されている
場合）には，全モデルが大幅に正答率を向上させて
いる．コンテキストがある場合は，gemini が最も高
い正答率となり，次いでgpt4, llama based が続いて
いる．コンテキストが無い場合は，相対的には変わ
らない結果となったが，正答率が約50%程度のタス
クであることが分かった．
本実験結果から，正答に必要な情報を与えること
で，LLM は人間とほぼ同等の正答率で回答を返す
ことが出来るが，pre-trained の gpt では，法令に関
する情報が不足していることが推測されるため，正
確な答えを返すまでには至らないことが分かった．
次に，各モデルの出力をアンサンブルした場合の結
表1 法令QA タスクの正答率(各モデル単体)
モデル コンテキストあり なし
llama based 81.4% 47.0%
gpt4 86.1% 49.3%
gemini1.5 95.0% 54.3%
果を表 2 に示す．Majority voting では，gpt4 単体モ
デルよりも若干高い正答率を示し，Soft voting 及び
Soft voting + 信頼度考慮によってさらにわずかな正
答率向上が得られた．また，単体の性能と比較する
と，gemini1.5 単体の方がアンサンブル手法よりも高
い精度になることが分かった．
本実験から，アンサンブル手法自体は有効ではあ
るが，単体性能がある程度高いモデル同士を利用す
る方が回答率のさらなる向上に寄与する可能性が高
いことを示唆している．
表2 法令QA タスクの正答率(アンサンブル)
モデル コンテキストあり なし
Majority voting 86.2% 51.3%
Soft voting 86.3% 51.4%
Soft voting+信頼度 86.6% 51.6%
5.4 実験 2: Ground Truth Curation の実
験と結果
実験1 で利用した3 つのモデルを使って，Ground
Truth の間違いが存在するのか実験を行った．実験1
から，現状のLLM はコンテキストが無いと高精度
に回答できないことが分かっているので，今回はコ
ンテキストありのテストデータを利用した．本実験
では，Ground Truth 以外の LLM のアウトプットが
2 つ以上一致している設問について抽出し，専門家
への回答の見直しを実施した．例えば，以下の事例
は，GT(Ground Truth) 以外すべてa と回答した事例
である．QID GT model1 model2 model3
金商法第6 章27 d a a a
結果を表5 に示す．全部で7 件(a,b,c,d をランダ
ムにする前の140 件中) が抽出された．表中の𝑄𝐼𝐷
が設問ID で，それに対して修正の必要性があった
かどうか，そして，修正の理由を記載している．表
からわかる通り，全7 件中4 件で何かしらの問題が
あることが分かった．この中で，最も致命的な回答
記載ミスが1 件，その他3 件も問題文の記載に不明
瞭な点があり，修正をしたものが3 件あった．誤検
知（実際はGround Truth があっていたもの）が3 件
あったが，その中には，問題文の解釈が難しいもの
（ex. 当てはまらないものを択一式で選択する）や，
コンテキストからは正しくないことしか判断できな
いもの等人間が見ても難しい問題が多く抽出されて
いた．
5.5 実験結果の考察
実験の結果，複数のLLM の回答を組み合わせる
ことで，(1) 単独モデルでは見逃していた問題点を
抽出しやすくなったこと，(2) Ground Truth 自体に含
まれる不備を効率的に発見できたことが分かった．
具体的には，不一致問題に対して再度専門家が検
証したところ，条文引用不足，答えラベルの単純ミ
ス，複数の選択肢が正解になるといったケースが確
認された．これは，法令QA タスクのように専門性
が高い領域において，人手で作成するGround Truth
にも一定のエラー率が含まれ得ることを示唆する．
6 結論
本研究では，複数のLLM を用いて法令QA タス
クのGround Truth を検証するアプローチを提案し，
実際に不備を含む問題を特定して修正した．法令の
ような専門領域では，問題作成の段階で誤りが混入
するリスクが高く，従来は専門家による時間的コス
トのかかる再検証が必要だった．しかし，LLM の
回答をアンサンブルし，不一致箇所を重点的に確認
する手法により，Ground Truth の正確性を効率的に
向上できることが示唆された．
今後の課題としては，(1) 法令ドメインに特化し
たLLM のさらなる性能向上，(2) モデルが生成する
根拠の自動評価手法の確立，(3) 法解釈の揺れが大
きい問題への対処などが挙げられる．いずれにせ
よ，本研究の結果は法令 QA タスクのデータキュ
レーションやLLM を活用した自動評価の有効性を
示すものであり，他の専門領域（医療，特許など）
にも応用可能な知見を提供する．― 2489 ―This work is licensed by the author(s) under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/).
参考文献
[1] Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo
Cho, Hwiyeol Jo, Sang-Woo Lee, Sang goo Lee, and Taeuk
Kim. Ground-truth labels matter: A deeper look into input-
label demonstrations, 2022.
[2] Changyue Song, Kaibo Liu, and Xi Zhang. Collusion detec-
tion and ground truth inference in crowdsourcing for label-
ing tasks. J. Mach. Learn. Res., Vol. 22, No. 1, January
2021.
[3] Randy Goebel, Yoshinobu Kano, Mi-Young Kim, Juliano
Rabelo, Ken Satoh, and Masaharu Yoshioka. Overview
of benchmark datasets and methods for the legal informa-
tion extraction/entailment competition (coliee) 2024. In
Toyotaro Suzumura and Mayumi Bono, editors, New Fron-
tiers in Artificial Intelligence, pp. 109–124, Singapore,
2024. Springer Nature Singapore.
[4] Stephen Tomlinson and Bruce Hedin. Measuring Ef-
fectiveness in the TREC Legal Track, pp. 167–180.
Springer Berlin Heidelberg, Berlin, Heidelberg, 2011.
[5] Jinliang Lu, Ziliang Pang, Min Xiao, Yaochen Zhu, Rui
Xia, and Jiajun Zhang. Merge, ensemble, and cooperate! a
survey on collaborative strategies in the era of large language
models, 2024.
[6] Wangyue Li, Liangzhi Li, Tong Xiang, Xiao Liu, Wei Deng,
and Noa Garcia. Can multiple-choice questions really be
useful in detecting the abilities of llms?, 2024.
表3 検証データにおける各モデルの信頼度
モデル コンテキストあり なし
llama based 84.3% 45.7%
gpt4 84.3% 50.0%
gemini1.5 91.0% 58.6%
表4 アンサンブル手法の比較
手法 数式 入力
Majority voting 𝑆𝑗=argmax𝑗
(∑𝑛𝑖=1 𝕀(𝑦𝑖=𝑗))全モデルの出力
Soft voting 𝑆𝑗=argmax𝑗(∑𝑛𝑖=1 𝑝𝑖,𝑗)モデルの確率出力 𝑝𝑖,𝑗
モデルの信頼度を考慮したSoft voting 𝑆𝑗=
∑𝑛𝑖=1 𝑤𝑖·𝑝𝑖,𝑗∑𝑛𝑖=1 𝑤𝑖, 𝑤𝑖=正解数𝑖
𝑁モデルの確率出力 𝑝𝑖,𝑗, 信頼度𝑤𝑖
表5 Ground Truth Curation 結果
QID 修正 理由
金商法第6 章73 No 誤検知
薬機法第5 章38 No 誤検知
薬機法第5 章46 Yes 問題文修正
金商法第6 章27 Yes 問題文修正
金商法第2 章34 No 誤検知
薬機法第15 章19 Yes 回答記載ミス
借地借家法第3 章19 Yes 問題文修正― 2490 ―This work is licensed by the author(s) under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/).