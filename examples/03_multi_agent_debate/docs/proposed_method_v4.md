# 提案手法 v4: 2エージェント構成による法令QA

## 概要

v4は、RetrieverAgentとIntegratorAgentの2エージェント構成により、法令QAの精度を向上させる手法です。

### 主要な特徴

1. **シンプルな2エージェント構成**
2. **質問タイプに応じた適応的処理**
3. **段階的な分析と統合判断**
4. **Hybrid検索（Vector + BM25）**

---

## アーキテクチャ

```
[質問入力]
    │
    v
[クエリ正規化] ─── 条文番号の漢数字変換
    │
    v
[Hybrid検索] ─── Vector + BM25 (RRF融合)
    │
    v
[RetrieverAgent]
    │  - 検索結果の分析
    │  - 質問タイプの判定
    │  - 各選択肢と条文のマッチング
    │  - 暫定回答の生成
    │
    v
[IntegratorAgent]
    │  - RetrieverAgentの分析を統合
    │  - 最終判断の実行
    │  - 回答の出力
    │
    v
[最終回答]
```

---

## コンポーネント詳細

### 1. クエリ正規化

条文番号のアラビア数字を漢数字に変換し、検索精度を向上させます。

```python
# 変換例
"第21条" → "第二十一条"
"第27条の5" → "第二十七条の五"
```

### 2. Hybrid検索

Vector検索とBM25検索を組み合わせ、RRF（Reciprocal Rank Fusion）で統合します。

| 検索方式 | 重み | 役割 |
|----------|------|------|
| Vector (FAISS) | 0.5 | 意味的類似性 |
| BM25 | 0.5 | キーワードマッチング |

### 3. RetrieverAgent

検索結果を分析し、質問に対する初期判断を行います。

#### 分析内容

1. **質問タイプ判定**
   - 誤り選択（誤っているものを選ぶ）
   - 正しい選択（正しいものを選ぶ）
   - 組み合わせ
   - 単純選択

2. **選択肢-条文マッチング**
   - 各選択肢に関連する条文を特定
   - 一致/不一致を判定

3. **暫定回答生成**
   - 分析に基づく暫定回答
   - 根拠の明示

#### プロンプト構造

```
【検索された条文】
{context}

【問題】
{question}

【選択肢】
{choices}

【質問タイプ】: {type}

分析:
1. 各選択肢に関連する条文を特定
2. 重要な数値・条件を抽出
3. 選択肢と条文の一致/不一致を確認
4. 暫定的な回答と根拠
```

### 4. IntegratorAgent

RetrieverAgentの分析を統合し、最終判断を行います。

#### 判断プロセス

1. RetrieverAgentの分析結果を確認
2. 質問タイプに応じた回答戦略を適用
3. 条文との整合性を最終確認
4. 回答を出力

---

## 質問タイプ別の処理

### 誤り選択

```
【目的】: 条文と一致しない選択肢を見つける
【戦略】: 各選択肢を条文と比較し、不一致のものを特定
```

### 正しい選択

```
【目的】: 条文と完全に一致する選択肢を見つける
【戦略】: 各選択肢の全ての記述が条文と一致するか確認
```

### 組み合わせ

```
【目的】: 正しい条件の組み合わせを見つける
【戦略】: 各条件を個別に検証し、全て正しい組み合わせを特定
```

---

## 実験結果

### 全体精度

| 指標 | 結果 |
|------|------|
| 正解数 | 103/140 |
| 精度 | **73.6%** |
| ベースライン比 | **+5.0%** |

### 範囲別精度

| 範囲 | v4 | Baseline | 改善 |
|------|-----|----------|------|
| Q1-Q30 | 63.3% | 43.3% | **+20%** |
| Q31-Q60 | 80.0% | 80.0% | 0% |
| Q61-Q90 | 76.7% | 73.3% | +3% |
| Q91-Q120 | 73.3% | 70.0% | +3% |
| Q121-Q140 | 75.0% | 80.0% | -5% |

### 変化パターン

| パターン | 問題数 | 意味 |
|----------|--------|------|
| 両方正解 | 82問 | 安定的に正解 |
| 両方不正解 | 23問 | 共通の弱点 |
| v4のみ正解 | 21問 | **改善** |
| BLのみ正解 | 14問 | 劣化 |

**ネット改善**: +7問

---

## v4の強み

### 1. Q1-30での大幅改善（+20%）

ベースラインが最も苦手だった範囲で大きな改善を達成。
2エージェント構成による段階的分析が効果的。

### 2. シンプルな構成

- 2エージェントのみで効率的
- 追加機能（Reranker、数値比較等）は逆効果
- LLMへの情報過多を防ぐ

### 3. 質問タイプ適応

質問タイプを判定し、適切な回答戦略を適用することで精度向上。

---

## v4の弱点

### 1. 共通弱点（23問）

両手法で不正解の問題:
- 複数条文にまたがる複雑な比較
- 数値の微妙な違いの判断
- 施行令等の参照関係

### 2. 劣化問題（14問）

v4で新たに不正解となった問題:
- 一部の単純問題での過剰処理の可能性

### 3. LLMの出力不安定性

同じ問題でも結果が変わる場合がある。

---

## 実装ファイル

| ファイル | 役割 |
|----------|------|
| `proposed_workflow_v4.py` | v4ワークフロー本体 |
| `proposed_workflow_v4_with_analysis.py` | v4 + 事後分析統合版 |
| `post_analysis.py` | 事後分析モジュール |
| `run_proposed_v4.py` | テスト実行スクリプト |
| `app/utils/number_normalizer.py` | 条文番号正規化 |

---

## 設定パラメータ

```python
WorkflowConfig(
    llm_model="qwen3:8b",     # LLMモデル
    timeout=180,               # タイムアウト（秒）
    num_ctx=16000,             # コンテキスト長
    top_k=30                   # 検索件数
)
```

---

## 追加機能テスト結果

v4に各機能を追加した場合の効果を検証:

| 手法 | Q1-10精度 | 結果 |
|------|-----------|------|
| **v4 (オリジナル)** | **90%** | **最良** |
| v4.1 (+ Reranker) | 40% | 逆効果 |
| v4.2 (+ 数値比較) | 60% | 逆効果 |
| v4 改善版 (プロンプト強化) | 60% | 逆効果 |

**結論**: v4のシンプルな構成が最も効果的。追加機能はLLMを混乱させる。

---

## バージョン比較

| バージョン | 精度 | 特徴 |
|------------|------|------|
| v1 (Baseline) | 68.6% | 単純RAG + CoT |
| v2 | 60.7% | 3エージェント + 議論ラウンド（過剰） |
| v3 | - | ChoiceVerifier（テスト不十分） |
| **v4** | **73.6%** | **2エージェント（最適）** |
| v5 | 64.0% | 適応的処理（逆効果） |

---

## 事後分析モジュール（Post-Analysis Module）

v4の精度を維持しつつ、**説明可能性と追跡可能性**を向上させる事後分析モジュールを実装。

### アーキテクチャ

```
[v4 ワークフロー]
    │
    v
[最終回答] ─────────────────┐
    │                      │
    v                      v
[ユーザーへ出力]    [事後分析モジュール]
                           │
                           ├── Citation Analysis（引用分析）
                           ├── Confidence Scoring（確信度評価）
                           └── Error Pattern Detection（エラーパターン検出）
                           │
                           v
                    [分析レポート]
```

### 1. Citation Analysis（引用分析）

LLMの応答から条文引用を自動抽出し、検証します。

```python
# 抽出パターン
"第二十四条第一項" → Citation(article_ref="第二十四条第一項", verified=True)

# 検証
- 引用がコンテキストに存在するか確認
- 引用内容と判断の整合性を評価
```

**提供価値**: 判断根拠の透明化、Hallucination検出

### 2. Confidence Scoring（確信度評価）

判断の信頼性を0.0〜1.0のスコアで算出します。

| 要素 | 影響 |
|------|------|
| 引用の有無・検証状況 | +0.2 (検証済み引用あり) |
| 回答の明確さ | +0.1 |
| 応答の長さ（適切な説明） | +0.1 |
| 高リスクキーワード | -0.05/個 |
| 質問タイプ（誤り選択/組み合わせ） | -0.05〜-0.1 |

**確信度レベル**:

| レベル | スコア | 意味 |
|--------|--------|------|
| HIGH | 0.8+ | 明確な根拠あり |
| MEDIUM | 0.5-0.8 | 部分的な根拠 |
| LOW | 0.3-0.5 | 根拠不明瞭 |
| VERY_LOW | 0-0.3 | 推測的（要レビュー） |

### 3. Error Pattern Detection（エラーパターン検出）

失敗しやすいパターンを事前検出し、警告を発します。

| パターン | 検出方法 | リスク |
|----------|----------|--------|
| multiple_articles | 「政令で定める」「施行令」等 | 複数条文参照 |
| numerical_comparison | 数字・期間・割合の存在 | 数値比較ミス |
| combination | 「組み合わせ」キーワード | 複合判断 |
| negation | 「誤っている」等 | 否定形問題 |

### 事後分析の実験結果（Q1-10）

| 確信度レベル | 正解/総数 | 正答率 | 洞察 |
|--------------|----------|--------|------|
| LOW | 7/8 | **88%** | 低確信度でも高正答率 |
| MEDIUM | 0/1 | 0% | 中確信度で不正解（警戒） |
| VERY_LOW | 0/1 | 0% | 適切に「要レビュー」警告 |

| エラーパターン | 正解/総数 | 正答率 | 洞察 |
|----------------|----------|--------|------|
| multiple_articles | 2/2 | 100% | 複数条文は得意 |
| **numerical_comparison** | **1/3** | **33%** | **苦手パターン** |
| combination | 0/1 | 0% | 組み合わせは難しい |
| negation | 1/2 | 50% | 否定形は中程度 |

### 不正解問題の警告例

```
Q6:
  予測=d, 正解=c
  確信度: 0.25 (VERY_LOW)
  パターン: [numerical_comparison, combination, negation]
  警告:
    - Caution: 数値比較を含む問題です（精査が必要）
    - Caution: 組み合わせ問題です（複合判断が必要）
    - Alert: 確信度が非常に低いです（要レビュー）
```

### 事後分析の価値

1. **リスク可視化**: 失敗しやすい問題を事前警告
2. **パターン特定**: 苦手パターン（数値比較=33%）を明確化
3. **説明可能性**: 判断根拠の透明化
4. **品質保証**: 低確信度問題の人間レビュー支援

### 実装ファイル

| ファイル | 役割 |
|----------|------|
| `post_analysis.py` | 事後分析モジュール本体 |
| `proposed_workflow_v4_with_analysis.py` | v4 + 事後分析統合版 |

---

## 今後の改善方向

### 短期的（実装可能）

1. **事後分析の活用**
   - 低確信度問題の人間レビュー
   - エラーパターン別の対策検討

2. **プロンプトの微調整**
   - 質問タイプ別の詳細なガイドライン
   - ただし追加情報は逆効果のため慎重に

3. **検索パラメータの最適化**
   - top_k、RRF重みの調整

### 中期的

1. **より大きなLLMモデル**
   - qwen3:14b / qwen3:32b
   - 複雑な推論能力の向上

2. **法令特化のReranker**
   - 汎用Rerankerは逆効果
   - 法令データでFine-tuning

### 長期的

1. **法令特化LLMのFine-tuning**
   - 法令QAデータセットでの調整
   - 期待改善: +10-15%

2. **検索精度の根本的改善**
   - より精密なチャンキング
   - 条文間の参照関係のグラフ化

---

## 学術的貢献

### 主要な貢献ポイント

1. **法令QA特化のマルチエージェント設計**
   - シンプルな2エージェント構成の有効性を実証
   - 追加機能が逆効果になることを示す（重要な知見）

2. **質問タイプ適応的処理**
   - 誤り選択/正しい選択/組み合わせの判定
   - タイプに応じた回答戦略

3. **事後分析による説明可能性**
   - 判断根拠の透明化
   - 確信度ベースの品質評価
   - エラーパターンの自動検出

### 論文向けの強調点

- **ドメイン特化**: 法令の構造的特性を活用
- **シンプルさの価値**: 複雑な手法が必ずしも有効でないことを実証
- **解釈可能性**: 事後分析による判断根拠の可視化
- **実用性**: 小規模LLM（8B）でベースライン+5%を達成

---

*最終更新: 2025/12/03*
