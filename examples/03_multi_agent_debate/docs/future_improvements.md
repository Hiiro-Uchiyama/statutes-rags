# 今後の性能向上策

## 現状分析

### ボトルネック特定

| 項目 | 現状 | 評価 |
|------|------|------|
| 検索精度 | 86.4% | 十分高い |
| LLM判断精度 | 85.2% | **改善余地あり** |
| 全体精度 | 73.6% | ベースライン+5% |

**主要ボトルネック**: LLMの判断精度

### 追加機能が逆効果になった理由

1. **情報過多**: 追加情報がLLMを混乱
2. **汎用Reranker**: 法令文書に最適化されていない
3. **複雑な処理**: シンプルな方が効果的

---

## 改善策の優先順位

### 即効性が高い（実装1日以内）

#### 1. より大きなLLMモデル

```python
# 現在
llm_model = "qwen3:8b"

# 推奨
llm_model = "qwen3:14b"  # または qwen3:32b
```

| モデル | パラメータ | 期待精度 |
|--------|------------|----------|
| qwen3:8b | 8B | 73.6% |
| qwen3:14b | 14B | 78-80% |
| qwen3:32b | 32B | 80-82% |

**期待改善**: +5-8%

#### 2. 温度パラメータの調整

```python
self.llm = Ollama(
    model=self.config.llm_model,
    temperature=0,  # 決定論的出力
    ...
)
```

**期待改善**: +1-2%（安定性向上）

#### 3. Few-shot例の追加

```python
prompt = f"""
【例題】
問題: 金融商品取引法第24条の規定について、正しいものを選んでください。
選択肢: a. 内国会社は三月以内, b. 外国会社は六月以内, ...
回答: b
理由: 施行令第3条の4により、外国会社は六月以内と規定されている。

【本題】
問題: {question}
...
"""
```

**期待改善**: +3-5%

---

### 中期的改善（1週間〜1ヶ月）

#### 4. 法令特化のFine-tuning

**方法**: LoRA/QLoRAを使用

```python
# Fine-tuningデータセット
{
    "instruction": "法令QAに回答してください",
    "input": "金融商品取引法第25条について...",
    "output": "正解はbです。理由は..."
}
```

**必要リソース**:
- 学習データ: 法令QAデータセット（500問以上）
- 計算: 8B モデルで数時間
- ツール: Hugging Face PEFT, Unsloth等

**期待改善**: +10-15%

#### 5. 法令特化のReranker

汎用Rerankerは逆効果だったため、法令データでFine-tuningが必要。

```python
# Fine-tuning対象
cross-encoder/ms-marco-MiniLM-L-6-v2

# 学習データ
[
    {"query": "金融商品取引法 有価証券報告書 提出期限",
     "positive": "第24条 三月以内に提出...",
     "negative": "第25条 縦覧書類..."}
]
```

**期待改善**: +2-3%

---

### 根本的改善（1ヶ月以上）

#### 6. 条文間参照関係のグラフ化

```
[金融商品取引法 第24条]
    │
    ├── 参照 → [施行令 第3条の4]
    │
    └── 参照 → [内閣府令 第...]
```

**実装**:
- 条文内の「政令で定める」等を検出
- 参照先を自動リンク
- グラフDBで管理

**期待改善**: +2-3%

#### 7. Self-RAG / RAG-Fusion

```python
# Self-RAG: 検索結果の自己評価
def self_rag(query, docs):
    # 1. 検索
    results = retrieve(query)
    
    # 2. 関連性評価
    relevant = llm.evaluate_relevance(query, results)
    
    # 3. 必要に応じて再検索
    if not relevant:
        expanded_query = llm.expand_query(query)
        results = retrieve(expanded_query)
    
    # 4. 回答生成
    return llm.generate(query, results)
```

**期待改善**: +3-5%

---

## 改善ロードマップ

```
現在: 73.6%
    │
    ├── [即時] 大きなLLM + 温度調整
    │       期待: 76-78%
    │
    ├── [1週間] Few-shot追加
    │       期待: 78-80%
    │
    ├── [1ヶ月] Fine-tuning
    │       期待: 83-88%
    │
    └── [3ヶ月] 全改善適用
            期待: 90%+
```

---

## 具体的な次のステップ

### Step 1: 大きなモデルでテスト（即時）

```bash
# qwen3:14bをダウンロード
ollama pull qwen3:14b

# v4をqwen3:14bで実行
# proposed_workflow_v4.pyのllm_modelを変更
```

### Step 2: Few-shot例の追加（1日）

各質問タイプに対して2-3個の例題を追加。

### Step 3: Fine-tuning環境構築（1週間）

```bash
pip install peft transformers datasets
```

法令QAデータセットを整形し、LoRAでFine-tuning。

---

## 共通弱点（23問）への対策

### 分析結果

| 特徴 | 件数 |
|------|------|
| 金融商品取引法関連 | 6問 |
| 複数条文比較 | 23問（全て） |
| 平均コンテキスト長 | 604文字 |

### 対策

1. **金融商品取引法の強化**
   - 施行令・規則を含めた統合検索
   - 条文番号の参照追跡

2. **複数条文比較の改善**
   - 検索結果のtop_k増加（30→50）
   - 複数クエリでの検索（各選択肢ごと）

3. **数値比較の精度向上**
   - より大きなLLMで改善期待
   - Fine-tuningで数値判断を強化

---

## まとめ

| 優先度 | 施策 | 期待改善 | 実装期間 |
|--------|------|----------|----------|
| 1 | 大きなLLM | +5-8% | 即時 |
| 2 | 温度=0 | +1-2% | 即時 |
| 3 | Few-shot | +3-5% | 1日 |
| 4 | Fine-tuning | +10-15% | 1ヶ月 |
| 5 | Self-RAG | +3-5% | 1ヶ月 |

**最も効果的**: Fine-tuning（+10-15%）
**最も即効性**: 大きなLLM（+5-8%、即時）

