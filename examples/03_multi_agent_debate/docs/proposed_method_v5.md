# 提案手法 v5: 適応的マルチエージェントワークフロー

## 概要

v5は、問題の複雑さに応じて処理を動的に切り替える適応的なマルチエージェントワークフローです。

### 主要な改善点

1. **Rerankerによる検索精度向上**
2. **問題複雑さに応じた処理分岐**
3. **数値抽出・比較の専用ロジック**
4. **関連条文の自動追加検索**

---

## アーキテクチャ

```
[質問入力]
    │
    v
[ComplexityAnalyzer] ─── 複雑さスコア計算
    │
    ├─── SIMPLE (score < 0.25)
    │       │
    │       v
    │    [SimpleRAG]
    │       - 基本検索
    │       - 直接回答生成
    │
    ├─── MODERATE (0.25 <= score < 0.5)
    │       │
    │       v
    │    [EnhancedRAG]
    │       - 検索 + Reranker
    │       - 数値比較
    │       - 強化プロンプト
    │
    └─── COMPLEX (score >= 0.5)
            │
            v
         [FullMultiAgent]
            - 検索 + Reranker
            - 関連条文追加検索
            - 数値比較
            - RetrieverAgent分析
            - IntegratorAgent統合
    │
    v
[最終回答]
```

---

## コンポーネント詳細

### 1. ComplexityAnalyzer（複雑さ分析器）

問題の複雑さを0.0〜1.0のスコアで評価します。

#### 評価要素

| 要素 | 重み | 説明 |
|------|------|------|
| 条文参照数 | +0.15〜0.30 | 4条文以上で+0.30 |
| 高複雑キーワード | +0.10/個 (max 0.30) | 「政令で定める」「施行令」など |
| 中複雑キーワード | +0.05/個 (max 0.15) | 「以内」「パーセント」など |
| 数値比較の存在 | +0.15 | 期間・割合の比較が必要 |
| 選択肢の長さ | +0.10 | 平均80文字以上 |
| 質問タイプ | +0.20 | 「組み合わせ」「複数条文比較」 |

#### 複雑さレベル

| レベル | スコア範囲 | 処理戦略 |
|--------|------------|----------|
| SIMPLE | < 0.25 | simple_rag |
| MODERATE | 0.25 - 0.50 | enhanced_rag |
| COMPLEX | >= 0.50 | full_multi_agent |

### 2. Reranker（再ランキング）

Cross-Encoderモデルを使用して検索結果を再ランキングします。

```python
# 使用モデル
cross-encoder/ms-marco-MiniLM-L-6-v2

# 処理フロー
1. Hybrid検索で候補取得（top_k=30）
2. Query-Document ペアをCross-Encoderでスコアリング
3. スコア順に再ソート
4. 上位20件を使用
```

#### 期待効果
- 関連度の高い条文が上位に
- 複数条文問題での精度向上

### 3. NumericExtractor（数値抽出器）

法令文書から数値情報を構造化して抽出します。

#### 対応パターン

| カテゴリ | パターン例 | 抽出結果 |
|----------|------------|----------|
| 期間 | 「三月以内」「6月」 | {value: 3, unit: "月", modifier: "以内"} |
| 割合 | 「五パーセント」「5%」 | {value: 5, unit: "%"} |
| 金額 | 「百万円」「1,000,000円」 | {value: 1000000, unit: "円"} |
| 条文 | 「第二十四条」「第24条」 | {article: 24} |

#### 漢数字変換

```python
"三" → 3
"十五" → 15
"二十四" → 24
"百二十" → 120
```

### 4. NumericComparator（数値比較器）

選択肢とコンテキスト間の数値を比較し、一致/不一致を判定します。

#### 出力例

```
【数値比較結果】
一致:
  - 六月以内 = 六月以内
不一致:
  - 選択肢: 三月以内 vs 条文: 六月以内 (差: -3)
```

### 5. RelatedArticleFinder（関連条文検索）

条文内の参照関係を追跡し、関連条文を自動検索します。

#### 検出パターン

| パターン | 例 | アクション |
|----------|-----|------------|
| 政令参照 | 「政令で定める」 | 施行令を検索 |
| 他条参照 | 「第24条の規定」 | 同法の該当条文を検索 |
| 他法参照 | 「民法第709条」 | 指定法令の条文を検索 |

---

## 処理戦略の詳細

### SimpleRAG（単純問題向け）

```
1. クエリ正規化（数字変換）
2. Hybrid検索（top_k=15）
3. シンプルプロンプトで回答生成
```

**対象**: 単一条文で明確に回答できる問題

### EnhancedRAG（中程度の問題向け）

```
1. クエリ正規化
2. Hybrid検索（top_k=20）
3. Rerankerで再ランキング
4. 数値比較情報を追加
5. 強化プロンプトで回答生成
```

**対象**: 数値比較が必要な問題、2-3条文の比較問題

### FullMultiAgent（複雑な問題向け）

```
1. クエリ正規化
2. Hybrid検索（top_k=30）
3. Rerankerで再ランキング
4. 関連条文の追加検索
5. 数値比較情報を生成
6. RetrieverAgent: 詳細分析
   - 質問タイプ判定
   - 選択肢-条文マッピング
   - 重要値の抽出
7. IntegratorAgent: 統合判断
   - 分析結果の統合
   - 最終回答決定
```

**対象**: 4条文以上、組み合わせ問題、施行令参照問題

---

## 実装ファイル

| ファイル | 役割 |
|----------|------|
| `app/retrieval/reranker.py` | Reranker実装 |
| `app/utils/complexity_analyzer.py` | 複雑さ分析器 |
| `app/utils/numeric_extractor.py` | 数値抽出・比較 |
| `app/utils/related_article_finder.py` | 関連条文検索 |
| `proposed_workflow_v5.py` | v5ワークフロー統合 |
| `run_proposed_v5.py` | テスト実行スクリプト |

---

## 期待される効果

### v4からの改善

| 項目 | v4 | v5（期待） | 改善理由 |
|------|-----|------------|----------|
| 全体精度 | 73.6% | 78-80% | 適応的処理+Reranker |
| 劣化問題 | 14問 | 7問以下 | 単純問題を適切に処理 |
| 共通弱点 | 23問 | 18問以下 | 数値比較+関連検索 |

### 戦略別期待精度

| 戦略 | 対象問題数（推定） | 期待精度 |
|------|-------------------|----------|
| simple_rag | 40-50問 | 80%+ |
| enhanced_rag | 50-60問 | 75-80% |
| full_multi_agent | 30-50問 | 70-75% |

---

## 設定パラメータ

```python
WorkflowConfig(
    llm_model="qwen3:8b",          # LLMモデル
    timeout=180,                    # タイムアウト（秒）
    num_ctx=16000,                  # コンテキスト長
    top_k=30,                       # 初期検索件数
    use_reranker=True,              # Reranker使用
    reranker_model="cross-encoder/ms-marco-MiniLM-L-6-v2"
)
```

---

## バージョン履歴

| バージョン | 精度 | 主な変更 |
|------------|------|----------|
| v1 (Baseline) | 68.6% | 単純RAG |
| v4 | 73.6% | 2-Agent構成 |
| v5 | 目標78%+ | 適応的処理+Reranker+数値比較+関連検索 |

