ベンチマーク用のRAG実装と今後方針のドキュメント一式を配置しました。

ドキュメントとコードを通読し、技術調査と事実確認を行ってください。
記載の正確性、実験条件の妥当性、設計と実装の整合、前提と仮説の反証可能性、今後の方向性と難所を重点的に精査をお願いします。
疑って読み、全体的な理解を深めて下さい。

[超重要]
このディレクトリに直接変更を加えないで下さい。
`legal-rag`をご自身の`/home/jovyan/work/`以下にコピーして使用して下さい。

``` bash
cp -r /home/jovyan/shared/legal-rag /home/jovyan/work/
```

[コピー後の動き]
`README.md`と`docs/`に格納しているドキュメントに目を通して下さい。
`SETUP.md`に従い、セットアップを進め、実際に動かす。
分からない点は各自調べながら理解を深め、今後どのような方向で進めていくか、検討して下さい。

[調査用]
理解を深めるために、界隈の最新情報を収集しましょうか。

[プロンプト：包括的な調査]
※ 各自〇〇部分は置き換えて下さい。生成AIを活用した調査、特に、Deep Researchを想定しています。

【目的】
法令データを活用した ①RAG ②AI Agent ③運用ワークフロー の最新動向と実装選択肢を、ビジネス要件と法的制約の下で比較評価し、短期PoC→MVPの推奨案を出す。

【前提（置換用）】
〇〇_関心テーマ = 「例：個人情報保護・労務・行政手続」
〇〇_ユースケース = 「例：根拠付きQA／規制検索／申請要件チェック」
〇〇_対象法領域 = 「例：個人情報保護法・労基法・道路使用許可」
〇〇_利用者像 = 「例：事務担当／法務／現場スタッフ」
〇〇_非機能要件 = 「SLO 99.9%、P95<2.5s、月額上限30万円」
〇〇_制約 = 「日本語優先、オンプレ可、データ持ち出し禁止」
〇〇_評価軸 = 「正確性、根拠忠実度、網羅性、レイテンシ、運用性、コスト」
〇〇_比較対象 = 「OSS, 商用SaaS, 自前構築」
〇〇_最新範囲 = 「直近12か月」

【タスク】
1) スコープ確定：上記の前提を明文化。含めない領域も列挙。
2) 情報源ランク付け：一次→公的（法令・官庁）／二次→論文・白書／三次→ベンダ資料・技術ブログ。信頼度をA/B/Cで付与。
3) 収集項目（MECE）  
   A. データ源：e-Gov法令XML、官報、判例、官庁FAQ、自治体要綱、民間Q&A。ライセンスと更新頻度。  
   B. 前処理：正規化、条文ID、改正トラッキング、版管理、分割（条→項→号）、脚注・様式の扱い。  
   C. 検索・索引：ベクトルDB候補（Qdrant/Milvus/pgvector）、BM25、ハイブリッド、メタデータ設計。  
   D. 埋め込み・再ランキング：日本語対応モデル候補、次元数、コスト、品質指標。  
   E. 生成モデル：日本語長文、引用整形、コンテキスト長、ツール使用（関数呼び出し）。  
   F. エージェント化：LangGraph/LangChain/Haystack、検証ループ、ツール群（規定検索、様式生成、チェックリスト）。  
   G. 評価：lawqa_jp等のベンチ、RAGAS系指標（忠実度・引用一致・再現率）、人手評価設計。  
   H. リスク・法務：個人情報保護、著作権・データ利用、弁護士法非該当性、説明責任、監査ログ。  
   I. 運用：監視（失敗クエリ、幻覚率）、ABテスト、改正差分反映SLA、災対。  
   J. コスト：推論・埋め込み・格納・帯域・運用人件費の月次試算。  
4) ベンダ／OSS比較：上記A–Jでスコアリング（5点満点）、重みは〇〇_評価軸に従い正規化。  
5) 典型アーキ案：  
   パス1 最小RAG、パス2 ハイブリッド＋再Ranker、パス3 Agent＋ワークフロー（申請様式自動化）。各パスでSLO/コスト達成可否を表に。  
6) 実験計画：チャンク長×overlap×top-k×再Ranker有無の直交表、最低n=50問の評価、停止基準を数値で設定。  
7) 推奨：短期PoC手順→MVP到達計画→運用To-Be。代替案と撤退条件も記載。  

【出力フォーマット】
1. TL;DR（5行）  
2. ランドスケープ表（A–J×候補）  
3. 推奨アーキ3案の比較表（SLO/品質/コスト/リスク）  
4. 実験設計表と実施チェックリスト  
5. リスク対策（法務・セキュリティ・運用）  
6. 次の一手（2週間ロードマップ）  
付録：用語集、引用URL、改正差分ログ設計

【検索クエリ自動生成（日本語/英語）】
以下の雛形で、それぞれ5–10件ずつ収集。site指定は必要に応じて増減。  
- 「site:e-gov.go.jp 〇〇_対象法領域 改正 〇〇_最新範囲」  
- 「site:cio.go.jp OR site:meti.go.jp OR site:dpia.go.jp ガイドライン 〇〇_ユースケース」  
- 「法令 XML スキーマ e-Gov RAG 前処理 事例」  
- 「RAG Japanese legal dataset evaluation lawqa_jp benchmark」  
- 「vector database qdrant milvus pgvector Japanese legal retrieval comparison」  
- 「reranker Japanese legal bge m3 e5 colbert evaluation」  
- 「LangGraph legal workflow compliance checklist」  
- 「判例 DB API サイト:*.go.jp OR site:courts.go.jp 〇〇_関心テーマ」  
- 「著作権 データベース 二次利用 官公庁 指針」  
- 「生成AI 法令 幻覚 防止 監査 ログ 設計」

【評価ルーブリック（各5点、重みは{w_i}）】
正確性、根拠忠実度、網羅性、説明可能性、レイテンシ、可用性、保守性、法令適合、TCO。総合=Σ w_i×score_i。

【チェックリスト】
- 改正差分を条・項単位で履歴化しているか  
- 参照条文・定義・別表をリンク復元できるか  
- 回答は逐条引用をインライン脚注で提示できるか  
- 失敗クエリの再学習ループがあるか  
- 外部データの権利・条項が台帳化されているか

【実行指示】
上記を順に実施。各節で「発見点／未解決／次アクション」を3行で締める。結論は一枚スライド要約も同時出力。

[プロンプト：情報補完]
※ 各自〇〇部分は置き換えて下さい。生成AIを活用した調査、特に、Deep Researchを想定しています。
※ こちらのプロンプトは対話型でも良いです。

【研究テーマ補完インタビュー（対話型）】
あなたは要件定義ファシリテータ。目的は、研究テーマ「〇〇_研究テーマ」と「〇〇_やりたいこと」に必要な情報の欠落を最小質問で特定し、仮置きで補完し、探索計画に落とすこと。
出力は日本語。箇条書きと表で簡潔に。

# 入力
- 〇〇_研究テーマ = 「例：法令データを用いたRAGの根拠忠実回答」
- 〇〇_やりたいこと = 「例：行政手続の要件判定を自動化」
- 〇〇_対象法領域 = 「例：個人情報保護、労務」
- 〇〇_想定利用者 = 「例：事務担当、法務」
- 〇〇_制約 = 「例：日本語優先、データ持出禁止、オンプレ可」
- 〇〇_環境 = 「例：Ollama+Qdrant、Supabase」

# 手順
1) 欠落情報の同定：MECEで不足を列挙（データ、評価、法務、実装、運用、組織）。
2) 質問最小化：同時に最大情報が得られる5問以内を提示。
3) 仮置き補完：公開情報の一般相場を用い、合理的なデフォルトを表で提案。
4) リスクと前提：暗黙の前提と失敗要因を明記。緩和策を併記。
5) 調査クエリ：優先度順に日英で5–10件ずつ生成。site指定を含める。
6) 次アクション：48時間以内の実行項目を3–5件。

# 出力フォーマット
A. 不足情報リスト（章立て）
B. 追加で聞くべき最小質問（<=5）
C. 仮置き補完テーブル
   | 項目 | 仮値 | 根拠 | 差替条件 |
D. 調査クエリ（JP/EN）
E. 直近タスク（担当/所要/成果物）